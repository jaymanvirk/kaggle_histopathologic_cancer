{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Histopathologic Cancer Detection: Simple CNN comparison","metadata":{}},{"cell_type":"markdown","source":"**Jay Manvirk (Ivan Loginov)**<br/>University of Colorado, Boulder<br/>jay.manvirk@gmail.com","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n\n1. [Abstract](#chapter_1)\n2. [Introduction](#chapter_2)\n3. [Libraries and raw data](#chapter_3)\n    - 3.1 [Libraries](#chapter_3_1)\n    - 3.2 [Raw data](#chapter_3_2)\n4. [Exploratory data analysis](#chapter_4)\n    - 4.1 [Short datasets summary](#chapter_4_1)\n    - 4.2 [Number of records per label](#chapter_4_2)\n    - 4.3 [Images](#chapter_4_3)\n5. [Data preprocessing](#chapter_5)\n    - 5.1 [Sampling](#chapter_5_1)\n    - 5.2 [Train-test split](#chapter_5_2)\n    - 5.3 [Parallel preprocessing](#chapter_5_3)\n6. [Model architecture](#chapter_6)\n    - 6.1 [Base model](#chapter_6_1)\n    - 6.2 [Dropout and batch normalization](#chapter_6_2)\n    - 6.3 [Tuned hyperparameters](#chapter_6_3)\n7. [Model results comparison](#chapter_7)\n    - 7.1 [Base model results](#chapter_7_1)\n    - 7.2 [Dropout and batch normalization results](#chapter_7_2)\n    - 7.3 [Tuned hyperparameters results](#chapter_7_3)\n    - 7.4 [Table results comparison](#chapter_7_4)\n8. [Submission Results](#chapter_8)\n9. [Conclusion](#chapter_9)\n10. [References](#chapter_10)","metadata":{}},{"cell_type":"markdown","source":"# 1. Abstract <a class=\"anchor\" id=\"chapter_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"Short summary. Goal. Results.","metadata":{}},{"cell_type":"markdown","source":"# 2. Introduction <a class=\"anchor\" id=\"chapter_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this notebook we're going to look at 3 simple CNN models' performance comparison:\n\n* Base model, which is going to include several basic layers\n* Regularized and normalized model, where we implement Dropout and Batch Normalization layers\n* Tuned model, layers of which are going to be the same as in the previous one, but with different parameters\n\nFor the sake of boosting the computational training speed of the aforementioned models we're going to incorporate Tensorflow parallelism and GPU accelerators.\n\nThis study is mainly focused on the brief analysis of the hyperparameters' impact on the model performance. It's going to be divided into several sections:\n* **Exploratory Data Analysis:**<br/>\nAs was mentioned in the preface of this dataset, the data has been already modified, so that it is duplicate-free. However, it's not enough to accept that data doesn't need any additional manipulation. Therefore we're going to look closer at the dataset internals for any additional cleaning or type conversion. Also we will examine the number of records per label to see whether the dataset needs sampling or not.\n* **Data preprocessing:**<br/>\nHere we will introduce 3 steps to improve future model trainings efficiency. Sampling, train-test split and parallel preprocessing.<br/>\nIn the Sampling section we will try to even number of records per label for better label representation during training. The train-test split section is presented only due to the reason, that we're not going to use cross validation. We will manually pass train and test sets directly to the models' fit function. And finally the first parallelism would be introduced in the parallel preprocessing section. It's going to be about how to utilize CPU cores efficiently to load images as fas as possible.\n* **Model Architecture:**<br/>\nThere will be an incremental update in every model except the base one. In essence they are supposed to be simple and straightforward, so that it's easier to spot the impact of the introduced updates and that this notebook doesn't take hours to run.\n* **Model results comparison:**<br/>\nThis section is going to be filled with train/test scores per epoch charts and final table with the fitted models' runtime and evaluated ROC AUC scores.","metadata":{}},{"cell_type":"markdown","source":"# 3. Libraries and data <a class=\"anchor\" id=\"chapter_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Libraries <a class=\"anchor\" id=\"chapter_3_1\"></a>","metadata":{}},{"cell_type":"code","source":"# basics\nimport os\nimport time\nimport numpy as np\n\n# EDA\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data preprocessing\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\n\n# Convolutional neural network\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers, models\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.optimizers import Adam\n\n# helper functions\nfrom PIL import Image\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:48:54.586565Z","iopub.execute_input":"2023-10-10T21:48:54.586920Z","iopub.status.idle":"2023-10-10T21:48:54.592948Z","shell.execute_reply.started":"2023-10-10T21:48:54.586890Z","shell.execute_reply":"2023-10-10T21:48:54.592113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Raw Data <a class=\"anchor\" id=\"chapter_3_2\"></a>","metadata":{}},{"cell_type":"code","source":"input_dir = '/kaggle/input/histopathologic-cancer-detection'\nlist_l = [os.path.join(input_dir, x) for x in os.listdir(input_dir)]\nlist_l","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:49:16.165934Z","iopub.execute_input":"2023-10-10T21:49:16.166293Z","iopub.status.idle":"2023-10-10T21:49:16.178060Z","shell.execute_reply.started":"2023-10-10T21:49:16.166268Z","shell.execute_reply":"2023-10-10T21:49:16.177038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = pd.read_csv(list_l[0])\ntrain_data = pd.read_csv(list_l[1])\ntrain_dir = list_l[3] + '/'\ntest_dir = list_l[2] + '/'","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:49:20.275581Z","iopub.execute_input":"2023-10-10T21:49:20.276206Z","iopub.status.idle":"2023-10-10T21:49:20.683604Z","shell.execute_reply.started":"2023-10-10T21:49:20.276176Z","shell.execute_reply":"2023-10-10T21:49:20.682614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Exploratory data analysis <a class=\"anchor\" id=\"chapter_4\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Short datasets summary <a class=\"anchor\" id=\"chapter_4_1\"></a>","metadata":{}},{"cell_type":"code","source":"def print_short_summary(name, data):\n    \"\"\"\n    Prints data head, shape and info.\n    Args:\n        name (str): name of dataset\n        data (dataframe): dataset in a pd.DataFrame format\n    \"\"\"\n    print(name)\n    print('\\n1. Data head:')\n    print(data.head())\n    print('\\n2. Data shape: {}'.format(data.shape))\n    print('\\n3. Data info:')\n    data.info()\n    \ndef print_number_files(dirpath):\n    print('{}: {} files'.format(dirpath, len(os.listdir(dirpath))))","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:15.963666Z","iopub.execute_input":"2023-10-10T21:39:15.964039Z","iopub.status.idle":"2023-10-10T21:39:15.969504Z","shell.execute_reply.started":"2023-10-10T21:39:15.964011Z","shell.execute_reply":"2023-10-10T21:39:15.968733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Train data', train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:19.054161Z","iopub.execute_input":"2023-10-10T21:39:19.054533Z","iopub.status.idle":"2023-10-10T21:39:19.078339Z","shell.execute_reply.started":"2023-10-10T21:39:19.054506Z","shell.execute_reply":"2023-10-10T21:39:19.077533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Sample data', sample_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:21.543450Z","iopub.execute_input":"2023-10-10T21:39:21.543804Z","iopub.status.idle":"2023-10-10T21:39:21.558315Z","shell.execute_reply.started":"2023-10-10T21:39:21.543776Z","shell.execute_reply":"2023-10-10T21:39:21.557521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_number_files(train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:23.853553Z","iopub.execute_input":"2023-10-10T21:39:23.853936Z","iopub.status.idle":"2023-10-10T21:39:26.208834Z","shell.execute_reply.started":"2023-10-10T21:39:23.853903Z","shell.execute_reply":"2023-10-10T21:39:26.208012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_number_files(test_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:28.845645Z","iopub.execute_input":"2023-10-10T21:39:28.846033Z","iopub.status.idle":"2023-10-10T21:39:28.873872Z","shell.execute_reply.started":"2023-10-10T21:39:28.846001Z","shell.execute_reply":"2023-10-10T21:39:28.873119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Number of records per label <a class=\"anchor\" id=\"chapter_4_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"The number of records per label differs signinficantly. This might create a problem in the model evaluation using ROC AUC score, if only one class is present in the dataset. We will address this scenario in the 5.1 Sampling section.","metadata":{}},{"cell_type":"code","source":"# Plot horizontal barplot of number of records per label\nplt.figure(figsize=(16, 9))\ntmp = train_data['label'].value_counts()\nsns.barplot(y=['No Cancer', 'Cancer'], x=tmp.values, orient='h')\nplt.xlabel('Number of records')\nplt.ylabel('Label')\nplt.title('Number of records per label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:32.126606Z","iopub.execute_input":"2023-10-10T21:39:32.127487Z","iopub.status.idle":"2023-10-10T21:39:32.328894Z","shell.execute_reply.started":"2023-10-10T21:39:32.127448Z","shell.execute_reply":"2023-10-10T21:39:32.328125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Images <a class=\"anchor\" id=\"chapter_4_3\"></a>","metadata":{}},{"cell_type":"code","source":"def get_images_to_plot(file_names):\n    \"\"\"\n    Returns list of images\n    Args:\n        file_names: list of filenames\n    Returns:\n        list of image objects\n    \"\"\"\n    return [Image.open(f) for f in file_names]\n\ndef get_image_label(dirname, data, labels, n = 5):\n    dict_img = {}\n    for l in labels:\n        indexes = data['label'] == l\n        tmp = data[indexes][:n]\n        tmp = dirname + tmp['id'] + '.tif'\n        tmp = tmp.values\n        tmp = get_images_to_plot(tmp)\n        dict_img[l] = tmp\n        \n    return dict_img","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:52.585199Z","iopub.execute_input":"2023-10-10T21:39:52.585592Z","iopub.status.idle":"2023-10-10T21:39:52.591918Z","shell.execute_reply.started":"2023-10-10T21:39:52.585561Z","shell.execute_reply":"2023-10-10T21:39:52.591015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print original image size\nimg_path = train_dir + train_data['id'][0] + '.tif'\nimg = Image.open(img_path)\nprint('Original image size: {}'.format(img.size))","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:54.983998Z","iopub.execute_input":"2023-10-10T21:39:54.984420Z","iopub.status.idle":"2023-10-10T21:39:55.014144Z","shell.execute_reply.started":"2023-10-10T21:39:54.984385Z","shell.execute_reply":"2023-10-10T21:39:55.013319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get 5 filenames per label\ndata = get_image_label(train_dir,train_data, [0,1])","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:57.011003Z","iopub.execute_input":"2023-10-10T21:39:57.011400Z","iopub.status.idle":"2023-10-10T21:39:57.043936Z","shell.execute_reply.started":"2023-10-10T21:39:57.011372Z","shell.execute_reply":"2023-10-10T21:39:57.043023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize subplots with 2 rows and 5 columns\nfig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 9))\n\n# Loop through the selected images and display in the respective rows\nlabels = ['No Cancer', 'Cancer']\nfor i in range(10):\n    row = i // 5\n    col = i % 5\n    axes[row, col].imshow(data[row][col])\n    axes[row, col].set_title(labels[row])\n    axes[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:39:59.094297Z","iopub.execute_input":"2023-10-10T21:39:59.094725Z","iopub.status.idle":"2023-10-10T21:40:00.015342Z","shell.execute_reply.started":"2023-10-10T21:39:59.094678Z","shell.execute_reply":"2023-10-10T21:40:00.014439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Data preprocessing <a class=\"anchor\" id=\"chapter_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Sampling <a class=\"anchor\" id=\"chapter_5_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"Downsampling or upsampling are about bias-variance trade-off. In the first one we reduce the number of records from the majority class. In the second one we replicate existing instances of minority class. In both cases we're trying to even number of labels to:\n* mitigate error of calculating ROC AUC score if there is only one label present in the selected set\n* improve model performance, be it better generalization (upsample) or faster training (downsample)\n\nIn our case the choice falls in favor of downsampling. Since we're dealing with simple CNN comparison our aim here is not the top performance algorithm, but rather an analysis of which model is more efficient. Thus we need to tune not just the models but the training data as well in order to reduce computational time as much as possible. Of course, all of that has to be done without significant loss in the ROC AUC score.","metadata":{}},{"cell_type":"code","source":"# Majority class\nno_cancer = train_data[train_data['label'] == 0]\n# Minority class\ncancer = train_data[train_data['label'] == 1]\n\n# Downsample majority class to match minority class\nno_cancer_downsampled = resample(no_cancer,\n                              replace=False, \n                              n_samples=len(cancer),\n                              random_state=0)\n\nbalanced_train_data = pd.concat([no_cancer_downsampled, cancer])\n\n# Shuffle train data for training\nbalanced_train_data = balanced_train_data.sample(frac=1, random_state=0).reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:07:57.448838Z","iopub.execute_input":"2023-10-10T22:07:57.449890Z","iopub.status.idle":"2023-10-10T22:07:57.506704Z","shell.execute_reply.started":"2023-10-10T22:07:57.449842Z","shell.execute_reply":"2023-10-10T22:07:57.505782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Train-test split <a class=\"anchor\" id=\"chapter_5_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"Since we're not going to rely on cross validation, we need to provide both train and test samples to CNN to measure overfitting during training. Thus we first split our train dataset into 75% and 25% of train and test data respectively based on the default values of function.","metadata":{}},{"cell_type":"code","source":"# Get full path to image including extension\nimage_paths = train_dir + balanced_train_data['id'] + '.tif'\nimage_paths = image_paths.values\n\nlabels = balanced_train_data['label'].values\n\nX_train, X_test, y_train, y_test = train_test_split(image_paths\n                                                    , labels\n                                                    , test_size = 0.25\n                                                    , shuffle = True\n                                                    , random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:08:04.023971Z","iopub.execute_input":"2023-10-10T22:08:04.024323Z","iopub.status.idle":"2023-10-10T22:08:04.124829Z","shell.execute_reply.started":"2023-10-10T22:08:04.024298Z","shell.execute_reply":"2023-10-10T22:08:04.123865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Parallel preprocessing <a class=\"anchor\" id=\"chapter_5_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"If we were to load images sequentially one-by-one or in batches, we would lose significant amount of time. Therefore it's more efficient to run this process in parallel, so that most of the time would be spent on actual training. With that in mind we're going to incorporate Tensorflow parallel processing functions to use optimal number of CPU cores provided in this notebook.\n\nAdditional important measures to increase training speed are the image resolution reduction and pixel scaling.<br/>Given our dataset of 96x96px images we can shrink them to 32x32px. It's an arbitrary reduction found across other kernels on Kaggle, but it helps in our case of speed-score trade-off.<br/>\nThe justification for pixel scaling lies in the idea of preventing gradients from becoming too large (exploding gradients) or too small (vanishing gradients) during backpropagation. Having this kind of constraint in the gradient values improve model performance overall.","metadata":{}},{"cell_type":"code","source":"def get_decoded_image(image_path, label=None):\n    \"\"\"\n    Load and preprocess images using TensorFlow I/O.\n    Decode image with 4 channels RGBA.\n    Resize image to 32x32px.\n    Scale pixels from 0 to 1.\n    Args:\n        image_path: path to TIFF image\n        label (optional): true label from train data\n    Returns:\n        (img, label): for train data\n        img: for test data\n    \"\"\"\n    img = tf.io.read_file(image_path)\n    img = tfio.experimental.image.decode_tiff(img)\n    img = tf.image.resize(img, [32, 32])\n    img = tf.cast(img, tf.float32) / 255.0\n    \n    return img if label is None else (img, label)\n\ndef get_prefetched_data(data, batch_size, buffer_size):\n    \"\"\"\n    Create a TensorFlow dataset from image paths and labels.\n    Execution in parallel.\n    Load, preprocess images, shuffle and batch the data.\n    Prefetch batches to improve training performance.\n    Args:\n        data (tuple): image paths and corresponding labels\n        batch_size (int): number of samples per batch\n        buffer_size (int): number of elements from the dataset to buffer while shuffling\n    Returns:\n        tf.data.Dataset: preprocessed and preloaded TensorFlow dataset for keras CNN\n    \"\"\"\n    # Autotune the degree of parallelism during training\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    \n    # Create dataset from image paths and labels\n    dataset = tf.data.Dataset.from_tensor_slices(data)\n\n    # Apply parallel processing to load and preprocess images\n    dataset = dataset.map(get_decoded_image, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.shuffle(buffer_size=buffer_size)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:49:49.398577Z","iopub.execute_input":"2023-10-10T21:49:49.399220Z","iopub.status.idle":"2023-10-10T21:49:49.407187Z","shell.execute_reply.started":"2023-10-10T21:49:49.399187Z","shell.execute_reply":"2023-10-10T21:49:49.405771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get train and test datasets for optimal performance\nBATCH_SIZE = 64\nTRAIN_BUFFER_SIZE = X_train.shape[0]\nTEST_BUFFER_SIZE = X_test.shape[0]\n\ntrain_dataset = get_prefetched_data((X_train, y_train)\n                                    , BATCH_SIZE\n                                    , TRAIN_BUFFER_SIZE)\ntest_dataset = get_prefetched_data((X_test, y_test)\n                                   , BATCH_SIZE\n                                   , TEST_BUFFER_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:08:12.647214Z","iopub.execute_input":"2023-10-10T22:08:12.647545Z","iopub.status.idle":"2023-10-10T22:08:12.725601Z","shell.execute_reply.started":"2023-10-10T22:08:12.647519Z","shell.execute_reply":"2023-10-10T22:08:12.724689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Model architecture <a class=\"anchor\" id=\"chapter_6\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Base model <a class=\"anchor\" id=\"chapter_6_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"Our base model is going to be simple CNN yet with several layers. All the parameters are based either on the default values of a model, common values among other works or dataset features.\nIt is going to be comprised of:\n\n1. **Convolutional Layers:**<br/>\nIt's said that Conv2D layer can capture spatial patterns in the input data. Ours is going to be with 32 filters of size (3, 3). The input shape (32, 32, 4) is used to address 32x32px images with 4 channels RGBA which were preprocessed by tfio.experimental.image.decode_tiff().\n2. **Pooling Layers:**<br/>\nThe MaxPooling2D layer focuses on the most important features. Our setup is the window size of (2,2) and the stride of (2,2) which are the default values. With that we reduce the spatial dimensions of the feature map by half in both width and height.\n3. **Flatten Layer:**<br/>\nThe Flatten layer transforms the 2D feature maps into a 1D vector, preparing the data for the subsequent dense layers.\n4. **Dense Layers:**<br/>\nThe first Dense layer with 64 and 128 units and the ReLU activation function enables the model to learn intricate relationships in the data. The final Dense layer with 1 unit and the sigmoid activation function is to output probability of having cancer in the image.\n7. **Activations:**<br/>\n* ReLU: introduces non-linearity into the model by replacing all negative values in the input with zero and supposedly computationally efficient<br/>\n* Sigmoid: within the range between 0 and 1 it represents the probability of belonging to the positive class, which is useful in our binary class problem\n\n6. **Loss Function and Optimizer:**<br/>\n* binary_crossentropy loss: forces the model to output probabilities close to 1 for cancer instances and close to 0 otherwise<br/>\n* adam optimizer: efficient and common optimization algorithm\n","metadata":{}},{"cell_type":"code","source":"def get_model_base():\n    # Define base CNN\n    model_base = models.Sequential([\n        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n        , layers.MaxPooling2D((2, 2))\n\n        , layers.Conv2D(64, (3, 3), activation='relu')\n        , layers.MaxPooling2D((2, 2))\n\n        , layers.Flatten()\n\n        , layers.Dense(64, activation='relu')\n        , layers.Dense(128, activation='relu')\n\n        , layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model_base","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:50:06.816330Z","iopub.execute_input":"2023-10-10T21:50:06.816680Z","iopub.status.idle":"2023-10-10T21:50:06.827513Z","shell.execute_reply.started":"2023-10-10T21:50:06.816653Z","shell.execute_reply":"2023-10-10T21:50:06.826404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Dropout and batch normalization <a class=\"anchor\" id=\"chapter_6_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"To tackle the problem of overfitting, we can add additional layer of Dropout Regularization. Dropout randomly sets a fraction of input units to 0 during training, which prevents model over adjusting its weights to train data. We're going to arbitrary set the dropout rate to 0.25, indicating that during training, 25% of the input units will be dropped out (set to 0).\n\nTo help solve another issue, slow training speed, we can add a layers of Batch Normalization. And thus normalize the activations of layers, making the optimization more efficient.","metadata":{}},{"cell_type":"code","source":"def get_model_drop_bn():\n    # Define CNN with dropout and batch normalization layers\n    model_drop_bn = models.Sequential([\n        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 4))\n        , layers.BatchNormalization()\n        , layers.MaxPooling2D((2, 2))\n\n        , layers.Conv2D(64, (3, 3), activation='relu')\n        , layers.BatchNormalization()\n        , layers.MaxPooling2D((2, 2))\n\n        , layers.Flatten()\n\n        , layers.Dense(64, activation='relu')\n        , layers.Dense(128, activation='relu')\n\n        , layers.Dropout(0.25)\n\n        , layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model_drop_bn","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:00:17.291420Z","iopub.execute_input":"2023-10-10T22:00:17.291772Z","iopub.status.idle":"2023-10-10T22:00:17.298608Z","shell.execute_reply.started":"2023-10-10T22:00:17.291744Z","shell.execute_reply":"2023-10-10T22:00:17.297543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3 Tuned hyperparameters <a class=\"anchor\" id=\"chapter_6_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this section we're going to tune several hyperparameters based on the previous network architecture. Concretely:\n1. **Number of filters in the Conv2D layer:**<br/>\nIncreasing the number of filters can allow the model to capture more complex patterns in the data. We're going to double the amount of each.\n2. **MaxPooling2d stride scale:**<br/>\nSmaller stride presents a trade-off of more details for increased computation, while larger stride offers the opposite. We're going to decrease stride from (2,2) to (1,1) to increase model ROC AUC score.\n3. **Dropout rate:**<br/>\nThe higher dropout rate the lower chances of overfitting. We're going to increase rate from 0.25 to 0.3.\n","metadata":{}},{"cell_type":"code","source":"def get_model_tuned():\n    # Define CNN with tuned hyperparameters\n    model_tuned = models.Sequential([\n        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 4))\n        , layers.BatchNormalization()\n        , layers.MaxPooling2D((2, 2), strides = (1,1))\n\n        , layers.Conv2D(128, (3, 3), activation='relu')\n        , layers.BatchNormalization()\n        , layers.MaxPooling2D((2, 2), strides = (1,1))\n\n        , layers.Flatten()\n\n        , layers.Dense(64, activation='relu')\n        , layers.Dense(128, activation='relu')\n\n        , layers.Dropout(0.3)\n\n        , layers.Dense(1, activation='sigmoid')\n    ])\n    \n    return model_tuned","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:00:22.087805Z","iopub.execute_input":"2023-10-10T22:00:22.088468Z","iopub.status.idle":"2023-10-10T22:00:22.094494Z","shell.execute_reply.started":"2023-10-10T22:00:22.088437Z","shell.execute_reply":"2023-10-10T22:00:22.093409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Model results comparison <a class=\"anchor\" id=\"chapter_7\"></a>","metadata":{}},{"cell_type":"code","source":"def roc_auc_score_(y_true, y_pred):\n    \"\"\"\n    Calculate ROC AUC score using sklearn built-in function.\n    Used in a model.compile as a custom metric.\n    Args:\n        y_true: true labels\n        y_pred: predicted labels\n    Returns:\n        ROC AUC score (float)\n    \"\"\"\n    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\n\ndef get_gpu_model(func):\n    \"\"\"\n    Create model to be trained with a multi-GPU strategy.\n    Args:\n        func: function to get model architecture\n    Returns:\n        compiled_model: tensorflow model that performs data parallelism\n                            by copying all of the model's variables\n                            to each processor\n    \"\"\"\n    # Check if GPU is available\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        # Create a MirroredStrategy.\n        strategy = tf.distribute.MirroredStrategy()\n\n        print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n    else:\n        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n        print('No GPU available, falling back to CPU.')\n\n    with strategy.scope():\n        compiled_model = func()\n        compiled_model.compile(optimizer='adam'\n                              , loss='binary_crossentropy'\n                              , metrics=['accuracy'])\n\n    return compiled_model","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:24:39.536150Z","iopub.execute_input":"2023-10-10T22:24:39.536543Z","iopub.status.idle":"2023-10-10T22:24:39.544449Z","shell.execute_reply.started":"2023-10-10T22:24:39.536513Z","shell.execute_reply":"2023-10-10T22:24:39.543433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_model_scores(scores, model_name):\n    \"\"\"\n    Plot train and test ROC AUC scores of a model by epoch\n    \"\"\"\n    train_scores, test_scores = scores\n    epochs = range(1, len(train_scores) + 1)\n\n    # Plot train and test scores\n    plt.figure(figsize=(16, 9))\n    plt.plot(epochs, train_scores, label='Train score')\n    plt.plot(epochs, test_scores, label='Test score')\n    plt.title('Train and test accuracy scores of {}'.format(model_name))\n    plt.xlabel('Epoch')\n    plt.ylabel('ROC AUC Score')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    \ndef get_model_results(model):\n    \"\"\"\n    Return tuple of runtime, train and test scores.\n    Compile, fit and save model along the way.\n    Args:\n        model: fitted model\n    Returns:\n        (runtime, (train_scores, test_scores) )\n    \"\"\"\n    model = get_gpu_model(model)\n    \n    st = time.time()\n    model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n    runtime = time.time() - st\n    \n    model.save('{}.h5'.format(model_name))\n    \n    train_scores = model.history.history['accuracy']\n    test_scores = model.history.history['val_accuracy']\n    \n    del model\n    \n    return (runtime, (train_scores, test_scores))","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:24:44.725806Z","iopub.execute_input":"2023-10-10T22:24:44.726876Z","iopub.status.idle":"2023-10-10T22:24:44.734899Z","shell.execute_reply.started":"2023-10-10T22:24:44.726834Z","shell.execute_reply":"2023-10-10T22:24:44.734014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.1 Base model results <a class=\"anchor\" id=\"chapter_7_1\"></a>","metadata":{}},{"cell_type":"code","source":"# Get train and test scores of every epoch\nruntime_base, scores_base = get_model_results(get_model_base)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:25:29.416016Z","iopub.execute_input":"2023-10-10T22:25:29.416963Z","iopub.status.idle":"2023-10-10T22:42:05.809849Z","shell.execute_reply.started":"2023-10-10T22:25:29.416922Z","shell.execute_reply":"2023-10-10T22:42:05.806371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot scores\nplot_model_scores(scores_base, 'base model')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:59:18.347909Z","iopub.execute_input":"2023-10-10T21:59:18.348925Z","iopub.status.idle":"2023-10-10T21:59:19.045628Z","shell.execute_reply.started":"2023-10-10T21:59:18.348882Z","shell.execute_reply":"2023-10-10T21:59:19.044752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2 Dropout and batch normalization results <a class=\"anchor\" id=\"chapter_7_2\"></a>","metadata":{}},{"cell_type":"code","source":"# Get train and test scores of every epoch\nruntime_drop_bn, scores_drop_bn = get_model_results(get_model_drop_bn)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:00:51.572411Z","iopub.execute_input":"2023-10-10T22:00:51.573313Z","iopub.status.idle":"2023-10-10T22:03:53.160067Z","shell.execute_reply.started":"2023-10-10T22:00:51.573282Z","shell.execute_reply":"2023-10-10T22:03:53.159169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot scores\nplot_model_scores(scores_drop_bn, 'regularized and normalized model')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:04:18.365958Z","iopub.execute_input":"2023-10-10T22:04:18.366339Z","iopub.status.idle":"2023-10-10T22:04:18.728989Z","shell.execute_reply.started":"2023-10-10T22:04:18.366312Z","shell.execute_reply":"2023-10-10T22:04:18.728100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.3 Tuned hyperparameters results <a class=\"anchor\" id=\"chapter_7_3\"></a>","metadata":{}},{"cell_type":"code","source":"# Get train and test scores of every epoch\nruntime_tuned, scores_tuned = get_model_results(get_model_tuned)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T22:04:38.552352Z","iopub.execute_input":"2023-10-10T22:04:38.553105Z","iopub.status.idle":"2023-10-10T22:05:22.341683Z","shell.execute_reply.started":"2023-10-10T22:04:38.553072Z","shell.execute_reply":"2023-10-10T22:05:22.340165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot scores\nplot_model_scores(scores_tuned)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:06:07.324748Z","iopub.execute_input":"2023-10-10T21:06:07.325357Z","iopub.status.idle":"2023-10-10T21:06:07.696302Z","shell.execute_reply.started":"2023-10-10T21:06:07.325261Z","shell.execute_reply":"2023-10-10T21:06:07.694805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4 Table results comparison <a class=\"anchor\" id=\"chapter_7_4\"></a>","metadata":{}},{"cell_type":"code","source":"table = [\n    {\n        'model':'Base'\n        , 'runtime': runtime_base\n        , 'train_roc_auc_score': scores_base[0][-1]\n        , 'test_roc_auc_score': scores_base[1][-1]\n    }\n    ,{\n        'model':'Drop and BN'\n        , 'runtime': runtime_drop_bn\n        , 'train_roc_auc_score': scores_drop_bn[0][-1]\n        , 'test_roc_auc_score': scores_drop_bn[1][-1]\n    }\n    ,{\n        'model':'Tuned'\n        , 'runtime': runtime_tuned\n        , 'train_roc_auc_score': scores_tuned[0][-1]\n        , 'test_roc_auc_score': scores_tuned[1][-1]\n    }\n]\n\npd.DataFrame(table).sort_values(by = ['test_roc_auc_score','runtime']\n                                , ascending = [False, True])","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:06:14.733548Z","iopub.execute_input":"2023-10-10T21:06:14.734008Z","iopub.status.idle":"2023-10-10T21:06:14.753443Z","shell.execute_reply.started":"2023-10-10T21:06:14.733977Z","shell.execute_reply":"2023-10-10T21:06:14.751734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Submission Results <a class=\"anchor\" id=\"chapter_8\"></a>","metadata":{}},{"cell_type":"markdown","source":"After loading model with tuned hyperparaters as the top one trained on 20% of the dataset, it predicted new labels with ROC AUC score of **0.5012**.\nAs can be clearly seen its predictive ability is just a fraction better than simply flipping a coin.","metadata":{}},{"cell_type":"code","source":"# Load save tuned model with custom metric parameter\nmodel_20 = load_model('drop_bn.h5'\n                           , custom_objects = {'roc_auc_score_': roc_auc_score_})","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:06:56.563396Z","iopub.execute_input":"2023-10-10T21:06:56.563864Z","iopub.status.idle":"2023-10-10T21:06:56.792533Z","shell.execute_reply.started":"2023-10-10T21:06:56.563834Z","shell.execute_reply":"2023-10-10T21:06:56.791145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create prefethed dataset of images to classify\nsubmis_data = test_dir + sample_data['id'] + '.tif'\nsubmis_data = submis_data.values\n\nBATCH_SIZE = 64\nSUBMIS_BUFFER_SIZE = submis_data.shape[0]\n\nsubmis_dataset = get_prefetched_data((submis_data)\n                                    , BATCH_SIZE\n                                    , SUBMIS_BUFFER_SIZE)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:07:01.794313Z","iopub.execute_input":"2023-10-10T21:07:01.795880Z","iopub.status.idle":"2023-10-10T21:07:01.890017Z","shell.execute_reply.started":"2023-10-10T21:07:01.795832Z","shell.execute_reply":"2023-10-10T21:07:01.888564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set predictions to result_20\nresult_20 = model_20.predict(submis_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:07:07.759892Z","iopub.execute_input":"2023-10-10T21:07:07.761187Z","iopub.status.idle":"2023-10-10T21:07:55.963469Z","shell.execute_reply.started":"2023-10-10T21:07:07.761129Z","shell.execute_reply":"2023-10-10T21:07:55.961965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create table of ids and labels like sample_submission\nsample_data['label'] = np.ravel(np.round(result_20))","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:08:21.623556Z","iopub.execute_input":"2023-10-10T21:08:21.624786Z","iopub.status.idle":"2023-10-10T21:08:21.631765Z","shell.execute_reply.started":"2023-10-10T21:08:21.624747Z","shell.execute_reply":"2023-10-10T21:08:21.630305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print submission table\nsample_data","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:08:30.613350Z","iopub.execute_input":"2023-10-10T21:08:30.614854Z","iopub.status.idle":"2023-10-10T21:08:30.630207Z","shell.execute_reply.started":"2023-10-10T21:08:30.614805Z","shell.execute_reply":"2023-10-10T21:08:30.628794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission\nsample_data.to_csv('submission_20.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T21:08:38.352158Z","iopub.execute_input":"2023-10-10T21:08:38.352711Z","iopub.status.idle":"2023-10-10T21:08:38.514456Z","shell.execute_reply.started":"2023-10-10T21:08:38.352673Z","shell.execute_reply":"2023-10-10T21:08:38.512917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Conclusion <a class=\"anchor\" id=\"chapter_9\"></a>","metadata":{}},{"cell_type":"markdown","source":"Short analysis of results. Possible explanation. Use in production.","metadata":{}},{"cell_type":"markdown","source":"# 10. References <a class=\"anchor\" id=\"chapter_10\"></a>","metadata":{}},{"cell_type":"markdown","source":"* Better performance with the tf.data API<br/>\nhttps://www.tensorflow.org/guide/data_performance\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}